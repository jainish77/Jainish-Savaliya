---
permalink: /
title: "About Me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


![Data Scientist Illustration](https://media.licdn.com/dms/image/v2/C4D12AQGD_su1k14bYA/article-cover_image-shrink_600_2000/article-cover_image-shrink_600_2000/0/1583217311227?e=1729728000&v=beta&t=FGnwE-u0SqMXlQRE33v2LkWvWcAou6AsDdrffUG4lvQ)



- Data Scientist with expertise in machine learning, statistical modeling, and big data engineering. Skilled in orchestrating end-to-end data pipelines, extracting insights from complex datasets, and developing predictive models to drive data-driven decisions. Adept at utilizing cutting-edge tools and technologies including Python, R, SQL, PySpark, TensorFlow, Hadoop, Spark, and cloud platforms like AWS.
- Proven ability to design scalable data solutions, exemplified by developing a high-performance pipeline to process 500GB of Reddit data with 98% accuracy.
  <img  src="../images/Illustation.jpg" alt="Data Scientist Illustration" width="300" align="right" style="margin: 0 0 10px 10px;" /> Experienced in transforming raw data to optimized formats like Parquet, accelerating query performance by 20%. Proficient in applying advanced analytics techniques like ensemble modeling to achieve over 80% predictive accuracy. 
- Committed to tackling intricate data challenges and delivering impactful, visualized insights. Previous projects encompassed domains like ecommerce analytics, urban taxi optimization, music streaming pipelines, and healthcare cost prediction. Passionate about leveraging data to solve real-world problems and consistently driving quantifiable improvements of 10-25% in key metrics.
- Possess strong technical skills complemented by excellence in communicating complex findings to diverse stakeholders. Looking to leverage my interdisciplinary expertise to unearth innovative data-driven solutions in a collaborative team environment.









- <p>
  
  - Data Scientist with expertise in machine learning, statistical modeling, and big data engineering. Skilled in orchestrating end-to-end data pipelines, extracting insights from complex datasets, and developing predictive models to drive data-driven decisions. Adept at utilizing cutting-edge tools and technologies including Python, R, SQL, PySpark, TensorFlow, Hadoop, Spark, and cloud platforms like AWS.
</p>
<p>
  - Proven ability to design scalable data solutions, exemplified by developing a high-performance pipeline to process 500GB of Reddit data with 98% accuracy. <img src="../images/Illustation.jpg" alt="Data Scientist Illustration" width="300" style="float: left; margin: 0 10px 10px 0;" />Experienced in transforming raw data to optimized formats like Parquet, accelerating query performance by 20%. Proficient in applying advanced analytics techniques like ensemble modeling to achieve over 80% predictive accuracy.
</p>
<p>
  - Committed to tackling intricate data challenges and delivering impactful, visualized insights. Previous projects encompassed domains like ecommerce analytics, urban taxi optimization, music streaming pipelines, and healthcare cost prediction. Passionate about leveraging data to solve real-world problems and consistently driving quantifiable improvements of 10-25% in key metrics.
</p>
<p>
  - Possess strong technical skills complemented by excellence in communicating complex findings to diverse stakeholders. Looking to leverage my interdisciplinary expertise to unearth innovative data-driven solutions in a collaborative team environment.
</p>



<!--## Data Scientist 

- **Expertise:** Machine Learning, Big Data Engineering 
- **Skills:** Python, R, SQL, PySpark, TensorFlow, Hadoop, Spark, AWS
- **Accomplishments:**
   - Designed scalable 500GB Reddit data pipeline with 98% accuracy
   - Optimized data formats (Parquet) for 20% faster querying
   - Proficient in advanced analytics (ensemble modeling, 80%+ predictive accuracy)
- **Experience:** 
   - Delivered visualized insights across e-commerce, urban mobility, music streaming, healthcare
   - Drove 10-25% metric improvements through data-driven solutions
- **Strengths:**
   - Strong technical skills 
   - Excellent at communicating complex findings
- **Goal:** Seeking collaborative role to innovate with interdisciplinary expertise -->

<!--**EDUCATION**

**Syracuse University,New York**
(August 2022 - May 2024)
- Master of Science | Information Systems | Advanced Certification in Data Science
- GPA: 3.7/4.0
- **Coursework:** Applied Machine Learning, Data Warehousing, Data Analytics & Decision Making, Database Management Systems

**Dharmsinh Desai University, India**
(July 2017 - May 2021)
- Bachelor of Technology | Instrumentation and Control Engineering
- GPA: 3.2/4.0
- **Coursework:** Microprocessor & Micro-Controller, Mathematics, Advanced C Programming, Robotics Engineering -->

<!-- Work experience
======

 ## Graduate Research Assistant, School of Information, New York (November 2023 – Present)
[C4 Lab](https://c4-lab.github.io/)
![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white) ![SQL](https://img.shields.io/badge/SQL-4479A1?style=flat&logo=postgresql&logoColor=white) ![Apache Parquet](https://img.shields.io/badge/Apache%20Parquet-AC6E2D?style=flat&logo=apache&logoColor=white) ![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=flat&logo=Apache%20Airflow&logoColor=white)

- Designing scalable data pipeline to extract and transform 500GB Reddit dataset (100M+ comments/submissions), aiming for 20% faster processing using zstandard compression and parallel processing techniques.
- Developing custom Python scripts to parse 150M JSON records with 98% accuracy, ensuring 95% overall data quality and integrity.
- Engineering efficient data storage solution by converting data to Apache Parquet format, optimizing for 15% better compression and 20% faster partition pruning to enable high-performance queries on 16core server.
- Validating transformed Parquet data by running 20+ SQL queries, confirming 98% data integrity and 90% queryability for downstream analysis and using structured 500GB dataset to build ML models forecasting Reddit user behavior and engagement.
- Presenting initial findings and 500GB Parquet dataset to professor, demonstrating suitability for predictive models with 80%+ accuracy.

## Programmer Analyst, India (June 2021 – April 2022)
[Saeculum Solutions Pvt Ltd](https://saeculumsolutions.com/)
![D3.js](https://img.shields.io/badge/D3.js-F9A03C?style=flat&logo=d3.js&logoColor=white) ![React](https://img.shields.io/badge/React-61DAFB?style=flat&logo=react&logoColor=white)

- Built D3.js & React front-end, Driving15% increase in user engagement &10% improvement in data-driven decisions.
- Conducted 10 A/B tests on web features, resulting in a 10% improvement in key metrics such as conversion rate and bounce rate.
- Collaborated cross-functionally to define data requirements, design analytics pipelines, and improve data-driven decisions by 20%.
- Presented 20 data analysis findings to stakeholders, influencing 50% of product roadmap decisions and marketing strategies. -->

# Work Experience


## Chat Bot Developer, Syracuse University, New York (June 2024 – Present)
![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white) ![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=flat&logo=streamlit&logoColor=white) ![OpenAI](https://img.shields.io/badge/OpenAI-00A3E0?style=flat&logo=openai&logoColor=white) ![Databricks](https://img.shields.io/badge/Databricks-FF9B00?style=flat&logo=databricks&logoColor=white)

- Improved setup efficiency by 40%, reducing onboarding time by 30% using Streamlit for deployment.
- Implemented short-term memory with OpenAI's LLM, enhancing bot response coherence by 50%.
- Created vector databases for Q&A bots, achieving 98% accuracy and reducing manual handling by 60%.

## Data Analyst, iConsult Collaborative, New York (September 2023 – June 2024)
![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white) ![Delta Lake](https://img.shields.io/badge/Delta%20Lake-00B2A9?style=flat&logo=apache&logoColor=white) ![Snowflake](https://img.shields.io/badge/Snowflake-00B2E2?style=flat&logo=snowflake&logoColor=white)

- Enhanced sales forecasting accuracy by 15%, leading to a 20% revenue growth through model tracking.
- Managed ETL pipelines, integrating data from 50+ sources while leveraging Snowflake for optimized querying.
- Boosted processing efficiency by 60% through performance bottleneck analysis.

## Data Engineer, C4 Lab, New York (November 2023 – May 2024)
![Spark](https://img.shields.io/badge/Spark-E25A1C?style=flat&logo=apache-spark&logoColor=white) ![Kubernetes](https://img.shields.io/badge/Kubernetes-326CE5?style=flat&logo=kubernetes&logoColor=white)

- Designed a Spark pipeline for a 500GB Reddit dataset, achieving 20% faster processing with zstandard.
- Parsed 150M JSON records with 95% data quality using PySpark, optimizing storage with Apache Parquet.
- Validated data integrity through SQL queries, ensuring high accuracy for machine learning models.

## Programmer Analyst, Saeculum Solutions Pvt Ltd, India (June 2021 – April 2022)
![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=flat&logo=fastapi&logoColor=white) ![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F20?style=flat&logo=tensorflow&logoColor=white)

- Engineered FastAPI-based APIs for recommendation systems, enhancing user engagement by 15%.
- Conducted A/B tests, optimizing key metrics such as conversion and bounce rates significantly.
- Led cross-functional teams to define data requirements, impacting 50% of product roadmap decisions.







---

Skills
====
**Methodologies:** SDLC, Agile, Waterfall

**Programming:** ![Python](https://img.shields.io/badge/-Python-3776AB?style=flat-square&logo=python&logoColor=white) ![R](https://img.shields.io/badge/-R-276DC3?style=flat-square&logo=r&logoColor=white) ![SQL](https://img.shields.io/badge/-SQL-4479A1?style=flat-square&logo=postgresql&logoColor=white) ![PySpark](https://img.shields.io/badge/-PySpark-E25A1C?style=flat-square&logo=apache-spark&logoColor=white) ![Scala](https://img.shields.io/badge/-Scala-DC322F?style=flat-square&logo=scala&logoColor=white)

**ML/AI:** ![TensorFlow](https://img.shields.io/badge/-TensorFlow-FF6F00?style=flat-square&logo=tensorflow&logoColor=white) ![PyTorch](https://img.shields.io/badge/-PyTorch-EE4C2C?style=flat-square&logo=pytorch&logoColor=white) ![scikit-learn](https://img.shields.io/badge/-scikit--learn-F7931E?style=flat-square&logo=scikit-learn&logoColor=white) Linear/Logistic Regression, Decision Trees, Time Series, Ensembles, Deep Learning

**Data Engineering:** ![Spark](https://img.shields.io/badge/-Spark-E25A1C?style=flat-square&logo=apache-spark&logoColor=white) ![Hadoop](https://img.shields.io/badge/-Hadoop-66CCFF?style=flat-square&logo=apache-hadoop&logoColor=white) ![Hive](https://img.shields.io/badge/-Hive-FDEE21?style=flat-square&logo=apache-hive&logoColor=black) ![Airflow](https://img.shields.io/badge/-Airflow-017CEE?style=flat-square&logo=apache-airflow&logoColor=white)

**Cloud:** ![AWS](https://img.shields.io/badge/-AWS-232F3E?style=flat-square&logo=amazon-aws&logoColor=white) (EC2, Lambda, S3, RDS, etc.) ![Docker](https://img.shields.io/badge/-Docker-2496ED?style=flat-square&logo=docker&logoColor=white)

**Databases:** ![MySQL](https://img.shields.io/badge/-MySQL-4479A1?style=flat-square&logo=mysql&logoColor=white) ![PostgreSQL](https://img.shields.io/badge/-PostgreSQL-336791?style=flat-square&logo=postgresql&logoColor=white) ![MongoDB](https://img.shields.io/badge/-MongoDB-47A248?style=flat-square&logo=mongodb&logoColor=white) ![Cassandra](https://img.shields.io/badge/-Cassandra-1287B1?style=flat-square&logo=apache-cassandra&logoColor=white)

**Visualization:** ![Tableau](https://img.shields.io/badge/-Tableau-E97627?style=flat-square&logo=tableau&logoColor=white) ![Power BI](https://img.shields.io/badge/-Power_BI-F2C811?style=flat-square&logo=power-bi&logoColor=black) ![Matplotlib](https://img.shields.io/badge/-Matplotlib-005A9C?style=flat-square&logo=matplotlib&logoColor=white) ![Seaborn](https://img.shields.io/badge/-Seaborn-3785B7?style=flat-square&logo=seaborn&logoColor=white)

**Tools:** ![NumPy](https://img.shields.io/badge/-NumPy-013243?style=flat-square&logo=numpy&logoColor=white) ![Pandas](https://img.shields.io/badge/-Pandas-150458?style=flat-square&logo=pandas&logoColor=white) ![SciPy](https://img.shields.io/badge/-SciPy-8CAAE6?style=flat-square&logo=scipy&logoColor=white) ![VSCode](https://img.shields.io/badge/-VS_Code-007ACC?style=flat-square&logo=visual-studio-code&logoColor=white) ![PyCharm](https://img.shields.io/badge/-PyCharm-000000?style=flat-square&logo=pycharm&logoColor=white) ![Sagemaker](https://img.shields.io/badge/-Sagemaker-232F3E?style=flat-square&logo=amazon-sagemaker&logoColor=white) ![Git](https://img.shields.io/badge/-Git-F05032?style=flat-square&logo=git&logoColor=white)

Projects
====
Click [here](https://jainish77.github.io/Jainish-Savaliya.github.io/markdown/) to explore my projects. 



<!--[![AWS Solutions Architect - Associate](https://images.credly.com/size/110x110/images/8b31b3de-94f0-48e5-a0f1-b8909cbfc88d/AWS-Solutions-Architect-Associate-2020.png)](https://www.credly.com/badges/96b584c0-52e2-4263-b607-eb3be97fbc6a)
[![Snowflake Hands on Essentials - Data Warehouse](https://images.credly.com/size/110x110/images/a5dcf1f2-4c06-4b1f-baa4-799b1a5baa1f/Snowflake-Essentials-2020.png)](https://www.credly.com/badges/554b5cb3-2b17-4fe4-b09f-58e682f8f08e)
[![Excel Associate (2019)](https://images.credly.com/size/110x110/images/c8b60f08-229d-4f15-bbf6-5ff378ea2f8d/MOS-Excel-Associate-2019.png)](https://www.credly.com/badges/2a11f6c7-23cb-450b-bf68-28542ef591bf) -->

